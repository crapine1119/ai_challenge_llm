# ai_challenge_llm
Design LLM service for HR Manager

### Promblem Definition

* in/out
    > Input:  [기업 정보] + [과거 채용 공고] + [사용자 질의]

    > Output: [맞춤형 채용 공고]

* Task
  - 기존 정보를 활용한 Entity Extraction + Rewriting 문제
  - Details
    1. Entity Extraction
    - 기업 정보, 채용 공고, 사용자 질의에서, 도메인에 맞는 정보들을 추출해야함
    2. 추출한 정보들을 기반으로 사용자 질의를 Re-writing 
    3. 앞서 생성한 결과들을 기반으로, 맞춤형 채용공고를 생성 후 제공


* Problem 1
  - 사용자 질의에는 부적절한 내용이 들어갈 수 있음.
    - 여기서 채용 도메인에 필요한 정보만을 찾아내는 것이 hallucination 방지를 위한 핵심이라고 생각
  
  - 기업 정보의 양이 얼마나 되는지 가늠하기 어렵고, 이에 포함되는 불필요한 정보들은 Noise로써 \
  hallucination의 원인이 될 것이라고 생각 (당연히 잘 정제해서 넣어야함) \
  이때, 임베딩을 활용한 RAG가 잘 작동할 지 고민해봐야함 (사실 정제하면 양이 크게 많을 것 같지 않은데, 너무 문서가 긴 경우도 테스트해봐야할 듯) 

  - 생성 단계에서, 기업 입장에서의 민감한 정보는 강하게 통제해야함 (미리 해당 엔티티 리스트를 뽑아놓고 강하게 통제하는 기술이 필요)
  
  - 또한 생성할 채용 공고에 대한 평가는, 사람마다 주관적인 기준이 다 다를 수 밖에 없음. \
  서비스 관점에서 여러가지 선택지를 만들어서 제공하거나, 사전 템플릿을 선택하고 만들도록 하는 것이 유저 입장에서의 만족도를 높이는데 도움이 될 것이라고 판단

  * (참고) 서비스 관점에서, 사용자의 편의를 위해 기업을 선택하면 과거 채용 공고를 선택할 수 있도록 만들어야함


* Problem 2
  - 실시간 사용성 UX: 서비스에서 실시간으로 수많은 요청이 LLM에 몰리는 경우, 응답 지연은 어쩔 수 없음
  
  - Gen AI 서비스의 병목을 근본적으로 해결하기 위해선 GPU가 필요하지만, 비용이 너무 크게 발생하며 하드웨어 관리를 위한 엔지니어까지 필요로함 (너무 비현실적)\
  따라서, batch 처리할 수 있는게 있는지 고민해봐야하며, stream 및 중간 결과를 실시간으로 보여주는 것은 필수적임 (ttft 중요)
  
  - 또한, Gen AI 기술은 근본적으로 100%의 결과를 도출할 수 없음. 그렇기 때문에 유저의 선택 및 검토가 반드시 필요하며, 이를 서비스에 녹여내는 것이 중요하다고 생각 \
  즉, 서비스의 흐름 및 유저와의 상호작용을 고려한 시스템 설계가 중요

  - 근본적으로, 토큰을 최대한 아낄 수 있는 방법을 고려해야함. 같은 요청이라도 토큰 수가 작다면 TTFT를 최대한 줄일 수 있음 \
  기술적으로는, 하드웨어를 늘리거나 여러 api key를 확보하여 안정성을 확보할 수는 있음 (그러나, 일반적인 기업의 관점에서 무수히 많은 api key를 활용하는 것은 어려움)\
  그렇다면 미리 생성해놓을 수 있는 데이터를 최대한 저장해놔야하고, 인사 담당자 관점에서의 workflow를 고려해서 설계해야함\
  반복되는 작업이라면? 직무별 정보나 템플릿을 미리 생성해놓는 방향\
  아니면 이전의 공고를 기반으로 일부만 수정하는 방향으로 토큰 사용량을 줄일 수 있을까?

  - (참고) 부하도를 상시 모니터링하고, 모델별 예측 사용량이 많으면 대기 시간을 제공하는것도 좋을 듯

* Workflow 초안
  - 기업 선택 (기업 문서) --- 직무/직급(연차) 선택 --- (채용 담당자 관점에서의 템플릿 제시: 사전에 LLM으로 생성된 기술 자격, 우대 요건 제시 + 사용자 프롬프트)   
                                            |--- 기업 문서가 크면 검색해서 줄임
  - 추천을 그대로 사용한다면 사전에 만들어 놓을 수 있고, 리소스 소비 없이 제공 가능 (스타일별로 2~3개를 미리 만들어놓음)
  - (코멘트) 사용자가 어떤 요청을 할 지 모르는데 의도 분류를 앞단에 해야하는걸까? 아니면 사용자에게 물어볼까? (예를 들어 사전 분석 템플릿으로 빠르게 생성! 또는 자연어 기반 생성)
  - (Optional) 과거 채용공고를 사용자가 선택해서 업데이트 해달라고 할 수도 있음. 그럼 일부만 변경하면 됨


* Workflow v2
  - 기업 선택 (기업 문서) --- 직무/직급(연차) 선택 --- 사용자에게 제안 (과거 기록 기반 템플릿, 커스텀 생성)
  1. 과거 기록 기반 템플릿 --- (기업 문서 + 과거 채용공고 기반) 미리 생성한 기술 자격, 우대 요건, 기업 인재상 등을 포함한 초안 제시 (3가지 제시: 간결, 디테일, 과거 채용공고 스타일)
     --- 사용자 수정 기능 (이때 필요하면 llm으로 이관) --- 수정한 내용 기반 즉시 생성

  2. 커스텀 생성: 완전 커스텀 및 실시간 생성으로 시간이 오래 걸릴 수 있다고 선택할 때 알려줘야함

    커스텀이라고 해도 인사담당자가 처음부터 생성하고 싶을까? 아니, 근데 1을 거절했는데 뭐를 원할까?

    추가로, 실시간성에는 난이도를 고려한 LLM 배치가 중요함 (단순 요약 및 대화에는 3B 정도만해도 충분함)
  
    또한, streaming이 아닌 대기 시간일 경우, 예측 시간을 대략적으로 제시하고 다른 작업을 할 수 있도록 백그라운드로 동작 (유사한 직무에서 인기있는 채용 공고 등의 요약문을 보여줌)

    이 때, 마무리 되면 알람으로 사용자에게 알림


* Ideation 
  - 1.에서 llm으로 이관할때 프롬프트를 받아야하는데, 부적절한 내용에 대해서 어떻게 감지할지, hallucination을 어떻게 처리할 지 고민 (필터링을 여기에 도입해야할까?)
  - 머신러닝으로 해결할 수 있는 문제는 없을까? 유사도 검색 기반의 간단한 추천으로 


* 설계 / 추상화
  - DB에서 직무/직급별 기술 / 사전 채용 공고 및 템플릿 등 미리 생성된걸 가져오는 기능 (service)
  - 가드레일: 가장 앞단과, 가장 마지막 단에 위치해서 부적절한 문장을 막아주는 기능 (to domain)
  - 기업 문서 -> 전처리해서 직무별 field (요구 역량 및 기술)들을 채워넣는 기능 (service)
  - JD 생성 기능
  > Service1: 기업 문서 -> 직무별 정보, 요구 역량/기술, 인재상 등 사전 추출 \
  > Service2: 조회 도메인을 활용해서 생성된 기업 정보, JD에 대한 카탈로그 제공 \
  > Service3: JD 생성/수정 \
  > Service4: 현재 LLM사용량 등 자원에 대한 정보를 제공 \
  > (Optional) Service4: 유사한 JD 포스팅