# ai_challenge_llm
Design LLM service for HR Manager

### Promblem Definition

* in/out
    > Input:  [기업 정보] + [과거 채용 공고] + [사용자 질의]

    > Output: [맞춤형 채용 공고]

* Task
  - 기존 정보를 활용한 Entity Extraction + Rewriting 문제
  - Task
    1. Entity Extraction 
  
       - 기업 정보, 채용 공고, 사용자 질의에서, 도메인에 맞는 정보들을 추출해야함
          
    2. 추출한 정보들을 기반으로 사용자 질의를 Re-writing 
    3. 앞서 생성한 결과들을 기반으로, 맞춤형 채용공고를 생성 후 제공


* Problem 1
  - 사용자 질의에는 부적절한 내용이 들어갈 수 있음.
    - 여기서 채용 도메인에 필요한 정보만을 찾아내는 것이 hallucination 방지를 위한 핵심이라고 생각
  
  - 기업 정보의 양이 얼마나 되는지 가늠하기 어렵고, 이에 포함되는 불필요한 정보들은 Noise로써 
  
      hallucination의 원인이 될 것이라고 생각 (당연히 잘 정제해서 넣어야함) 

      이때, 임베딩을 활용한 RAG가 잘 작동할 지 고민해봐야함 (사실 정제하면 양이 크게 많을 것 같지 않은데, 너무 문서가 긴 경우도 테스트해봐야할 듯) 

  - 생성 단계에서, 기업 입장에서의 민감한 정보는 강하게 통제해야함 (미리 해당 엔티티 리스트를 뽑아놓고 강하게 통제하는 기술이 필요)
  
  - 또한 생성할 채용 공고에 대한 평가는, 사람마다 주관적인 기준이 다 다를 수 밖에 없음.

    서비스 관점에서 여러가지 선택지를 만들어서 제공하거나, 사전 템플릿을 선택하고 만들도록 하는 것이 유저 입장에서의 만족도를 높이는데 도움이 될 것이라고 판단

  * (참고) 서비스 관점에서, 사용자의 편의를 위해 기업을 선택하면 과거 채용 공고를 선택할 수 있도록 만들어야함


* Problem 2
  - 실시간 사용성 UX: 서비스에서 실시간으로 수많은 요청이 LLM에 몰리는 경우, 응답 지연은 어쩔 수 없음
  
  - Gen AI 서비스의 병목을 근본적으로 해결하기 위해선 GPU가 필요하지만, 비용이 너무 크게 발생하며 하드웨어 관리를 위한 엔지니어까지 필요로함 (너무 비현실적)
  - 따라서, batch 처리할 수 있는게 있는지 고민해봐야하며, stream 및 중간 결과를 실시간으로 보여주는 것은 필수적임 (ttft 중요)
  
  - 또한, Gen AI 기술은 근본적으로 100%의 결과를 도출할 수 없음. 그렇기 때문에 유저의 선택 및 검토가 반드시 필요하며, 이를 서비스에 녹여내는 것이 중요하다고 생각
  - 즉, 서비스의 흐름 및 유저와의 상호작용을 고려한 시스템 설계가 중요

